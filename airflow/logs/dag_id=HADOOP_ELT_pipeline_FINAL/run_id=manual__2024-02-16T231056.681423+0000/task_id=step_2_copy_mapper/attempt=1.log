[2024-02-16T23:11:07.587+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: HADOOP_ELT_pipeline_FINAL.step_2_copy_mapper manual__2024-02-16T23:10:56.681423+00:00 [queued]>
[2024-02-16T23:11:07.591+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: HADOOP_ELT_pipeline_FINAL.step_2_copy_mapper manual__2024-02-16T23:10:56.681423+00:00 [queued]>
[2024-02-16T23:11:07.623+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: HADOOP_ELT_pipeline_FINAL.step_2_copy_mapper manual__2024-02-16T23:10:56.681423+00:00 [queued]>
[2024-02-16T23:11:07.624+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2024-02-16T23:11:07.625+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: HADOOP_ELT_pipeline_FINAL.step_2_copy_mapper manual__2024-02-16T23:10:56.681423+00:00 [queued]>
[2024-02-16T23:11:07.626+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2024-02-16T23:11:07.688+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): step_2_copy_mapper> on 2024-02-16 23:10:56.681423+00:00
[2024-02-16T23:11:07.701+0000] {standard_task_runner.py:60} INFO - Started process 1066 to run task
[2024-02-16T23:11:07.703+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'HADOOP_ELT_pipeline_FINAL', 'step_2_copy_mapper', 'manual__2024-02-16T23:10:56.681423+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/ELT_automated_airflow.py', '--cfg-path', '/tmp/tmpeazh8pzl']
[2024-02-16T23:11:07.706+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask step_2_copy_mapper
[2024-02-16T23:11:07.744+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): step_2_copy_mapper> on 2024-02-16 23:10:56.681423+00:00
[2024-02-16T23:11:07.752+0000] {standard_task_runner.py:60} INFO - Started process 1067 to run task
[2024-02-16T23:11:07.762+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'HADOOP_ELT_pipeline_FINAL', 'step_2_copy_mapper', 'manual__2024-02-16T23:10:56.681423+00:00', '--job-id', '16', '--raw', '--subdir', 'DAGS_FOLDER/ELT_automated_airflow.py', '--cfg-path', '/tmp/tmp9b0ajgg4']
[2024-02-16T23:11:07.772+0000] {standard_task_runner.py:88} INFO - Job 16: Subtask step_2_copy_mapper
[2024-02-16T23:11:07.908+0000] {task_command.py:423} INFO - Running <TaskInstance: HADOOP_ELT_pipeline_FINAL.step_2_copy_mapper manual__2024-02-16T23:10:56.681423+00:00 [running]> on host a1bb76e936e6
[2024-02-16T23:11:07.921+0000] {task_command.py:423} INFO - Running <TaskInstance: HADOOP_ELT_pipeline_FINAL.step_2_copy_mapper manual__2024-02-16T23:10:56.681423+00:00 [running]> on host a1bb76e936e6
[2024-02-16T23:11:08.147+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.IntegrityError: UNIQUE constraint failed: rendered_task_instance_fields.dag_id, rendered_task_instance_fields.task_id, rendered_task_instance_fields.run_id, rendered_task_instance_fields.map_index

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2334, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2469, in _execute_task_with_callbacks
    RenderedTaskInstanceFields.write(rtif)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/contextlib.py", line 120, in __exit__
    next(self.gen)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 39, in create_session
    session.commit()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3589, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) UNIQUE constraint failed: rendered_task_instance_fields.dag_id, rendered_task_instance_fields.task_id, rendered_task_instance_fields.run_id, rendered_task_instance_fields.map_index
[SQL: INSERT INTO rendered_task_instance_fields (dag_id, task_id, run_id, map_index, rendered_fields, k8s_pod_yaml) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: ('HADOOP_ELT_pipeline_FINAL', 'step_2_copy_mapper', 'manual__2024-02-16T23:10:56.681423+00:00', -1, '{"templates_dict": null, "op_args": [], "op_kwargs": {}}', 'null')]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2024-02-16T23:11:08.165+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='HADOOP_ELT_pipeline_FINAL' AIRFLOW_CTX_TASK_ID='step_2_copy_mapper' AIRFLOW_CTX_EXECUTION_DATE='2024-02-16T23:10:56.681423+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-02-16T23:10:56.681423+00:00'
[2024-02-16T23:11:08.180+0000] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=HADOOP_ELT_pipeline_FINAL, task_id=step_2_copy_mapper, execution_date=20240216T231056, start_date=20240216T231107, end_date=20240216T231108
[2024-02-16T23:11:08.188+0000] {logging_mixin.py:188} INFO - Error occurred: Command 'hadoop fs -put C:\Users\LENOVO\ETL-and-ELT-integration-pipelines\mapper.py /python' returned non-zero exit status 127.
[2024-02-16T23:11:08.189+0000] {python.py:201} INFO - Done. Returned value was: None
[2024-02-16T23:11:08.224+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=HADOOP_ELT_pipeline_FINAL, task_id=step_2_copy_mapper, execution_date=20240216T231056, start_date=20240216T231107, end_date=20240216T231108
[2024-02-16T23:11:08.240+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 16 for task step_2_copy_mapper ((sqlite3.IntegrityError) UNIQUE constraint failed: rendered_task_instance_fields.dag_id, rendered_task_instance_fields.task_id, rendered_task_instance_fields.run_id, rendered_task_instance_fields.map_index
[SQL: INSERT INTO rendered_task_instance_fields (dag_id, task_id, run_id, map_index, rendered_fields, k8s_pod_yaml) VALUES (?, ?, ?, ?, ?, ?)]
[parameters: ('HADOOP_ELT_pipeline_FINAL', 'step_2_copy_mapper', 'manual__2024-02-16T23:10:56.681423+00:00', -1, '{"templates_dict": null, "op_args": [], "op_kwargs": {}}', 'null')]
(Background on this error at: https://sqlalche.me/e/14/gkpj); 1067)
[2024-02-16T23:11:08.257+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-02-16T23:11:08.323+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-02-16T23:11:08.337+0000] {taskinstance.py:3280} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-02-16T23:11:08.386+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
